# Прогнозирование выработки газа на скважинах

## Описание проекта

В этом проекте мы занимаемся прогнозированием выработки газа на скважинах для компании «Газ-Таз-Ваз-Нефть», используя данные о характеристиках скважин. Цель состоит в том, чтобы оценить, какие факторы влияют на объем добычи газа, а также в оптимизации расходов и повышении дохода компании.

Проект включает в себя применение различных линейных моделей для прогнозирования целевого признака - выработки газа (Prod) на основе других характеристик скважин.

## Данные

Набор данных включает следующие признаки:

- **Well**: идентификатор скважины
- **Por**: пористость скважины (%)
- **Perm**: проницаемость скважины
- **AI**: акустический импеданс ($кг/м^2 * 10^6$)
- **Brittle**: коэффициент хрупкости скважины (%)
- **TOC**: общий органический углерод (%)
- **VR**: коэффициент отражения витринита (%)
- **Prod**: добыча газа в сутки (млн. кубических футов)

## Постановка задачи

Для достижения поставленной задачи были рассмотрены и выбраны четыре линейные модели: линейная регрессия, Lasso, Ridge и ElasticNet. Все модели были обучены с использованием полиномиальных признаков для повышения качества прогнозов.

## Результаты

### Сравнение моделей по MAPE

- **Линейная регрессия**: MAPE 0.34% (обучающая выборка), 2.66% (валидационная выборка)
- **Lasso**: alpha=1.062, MAPE 1.46% (обучающие фолды), 1.73% (валидационные фолды)
- **Ridge**: alpha=0.621, MAPE 1.55% (обучающие фолды), 1.89% (валидационные фолды)
- **ElasticNet**: alpha=1.062, l1_ratio=1.000, MAPE 1.46% (обучающие фолды), 1.73% (валидационные фолды)

### Наилучший результат

Несмотря на наименьший MAPE на обучающей выборке, линейная регрессия показала значительно более высокую ошибку на валидационных данных (2.66%) по сравнению с Lasso и ElasticNet (по 1.73%). Это указывает на то, что модель, хотя и работает хорошо на обучающих данных, может иметь низкую устойчивость к новым данным.

### Переобученность

Модели Lasso и ElasticNet продемонстрировали высокую стабильность и меньшую предрасположенность к переобучению, так как MAPE на валидационной выборке лишь незначительно превышала значения на обучающей выборке.

## Заключение

Среди рассмотренных линейных моделей Lasso и ElasticNet показали лучшие результаты на валидационных фолдах при умеренном уровне переобученности, что свидетельствует о их эффективности при обработке полиномиальных признаков. Хотя линейная регрессия показала хорошие результаты на обучающих данных, её устойчивость к новым данным оставляет желать лучшего. Мы рекомендуем использовать ElasticNet за его гибкость и способность к уменьшению влияния ненужных признаков.

## Запуск Jupyter Notebook

Для запуска анализа откройте файл `Lin_Algeb-gas-product.ipynb` в Jupyter Notebook. Убедитесь, что все необходимые библиотеки установлены.

